#!/bin/bash

################################################################################################
### sbatch configuration parameters must start with #SBATCH and must precede any other commands.
### To ignore, just add another # - like so: ##SBATCH
################################################################################################

#SBATCH --partition main				### specify partition name where to run a job. main: all nodes; gtx1080: 1080 gpu card nodes; rtx2080: 2080 nodes; teslap100: p100 nodes; titanrtx: titan nodes
#SBATCH --time 5-00:00:00				### limit the time of job running. Make sure it is not greater than the partition time limit!! Format: D-H:MM:SS
#SBATCH --job-name semisupervised_double_descent_job	### name of the job
#SBATCH --output ../logs/jobs/job-%J.out			### output log for running job - %J for job number
#SBATCH --gpus=1					### number of GPUs, allocating more than 1 requires IT team's permission

# Note: the following 4 lines are commented out
##SBATCH --mail-user=paney@post.bgu.ac.il	### user's email for sending job status messages
##SBATCH --mail-type=ALL			### conditions for sending the email. ALL,BEGIN,END,FAIL, REQUEU, NONE
##SBATCH --mem=24G				### ammount of RAM memory, allocating more than 60G requires IT team's permission

### Print some data to output file ###
echo `date`
echo -e "\nSLURM_JOBID:\t\t" $SLURM_JOBID
echo -e "SLURM_JOB_NODELIST:\t" $SLURM_JOB_NODELIST "\n\n"

### Start your code below ####
module load anaconda				### load anaconda module (must be present when working with conda environments)
module load cuda/11.3
source activate LaplaceNet				### activate a conda environment
python main.py --dataset cifar10 --model wrn-28-2 --num-labeled 45000 --alpha 1.0 --lr 0.15 --labeled-batch-size 50 --batch-size 300 --aug-num 3 --label-split 12 --progress False